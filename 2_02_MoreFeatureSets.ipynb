{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec0'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing n-class word extraction functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#sec1'><b>1. Extraction by frequency differences between classes</b></a>\n",
    "   - Thresholds for minimum fraction of documents appearing or per-doc frequency\n",
    "   - Threshold with absolute difference (by subtraction) or relative/fold difference (by division)\n",
    "\n",
    "<a href='#sec2'><b>2. Extraction by exclusive appearances in certain classes</b></a>\n",
    "   - Threshold for minimum fraction of documents appearing or per-doc frequency\n",
    "   \n",
    "<a href='#sec3'><b>3. Classification by Random Forest Classifier</b></a>\n",
    "   1. <a href='#sec3_1'>RFC with exclusive words</a>\n",
    "   2. <a href='#sec3_2'>RFC with words selected by relative difference - fraction of docs appearing</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as scs\n",
    "import matplotlib.pyplot as plt\n",
    "import mskcc_functions as ski\n",
    "import feature_engineering as fe\n",
    "import xgboost as xgb\n",
    "\n",
    "from importlib import reload\n",
    "from xgboost import plot_importance\n",
    "from pprint import pprint\n",
    "from matplotlib  import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import Counter\n",
    "from gensim import corpora, matutils, models, similarities\n",
    "from nltk import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import scale, normalize, robust_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<input>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "<ipython-input-2-45d7f3e0e033>:2: DeprecationWarning: invalid escape sequence \\|\n",
      "  text_train = pd.read_csv(\"./data/training_text\", sep=\"\\|\\|\", engine='python',\n"
     ]
    }
   ],
   "source": [
    "class_train = pd.read_csv('./data/training_variants')\n",
    "text_train = pd.read_csv(\"./data/training_text\", sep=\"\\|\\|\", engine='python',\n",
    "                         header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "train = class_train.merge(text_train, on='ID')\n",
    "\n",
    "# create class label container\n",
    "class_labels = []\n",
    "for i in range(9):\n",
    "    class_labels.append('class' + str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/classified_docs.json') as f1:\n",
    "    classified_docs = json.load(f1)\n",
    "\n",
    "with open('./data/classified_tokenized_docs.json') as f2:\n",
    "    classified_tokenized_docs = json.load(f2)\n",
    "\n",
    "with open('./data/classified_texts.json') as f3:\n",
    "    classified_texts = json.load(f3)\n",
    "\n",
    "with open('./data/classified_tokenized_texts.json') as f4:\n",
    "    classified_tokenized_texts = json.load(f4)\n",
    "\n",
    "with open('./data/average_per_document_appearances.json') as f5:\n",
    "    ave_perdoc_apps = json.load(f5)\n",
    "    \n",
    "with open('./data/fraction_of_documents_with_appearance.json') as f6:\n",
    "    app_freqs = json.load(f6)\n",
    "\n",
    "with open(\"./data/unclassified_tokenized_docs.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    unclassified_tokenized_docs = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# intersecting words among top%d appearing words in each class:  1391\n",
      "# intersecting words with >50% appearance:  287\n",
      "Table shape before removal:  (125448, 9)\n",
      "Table shape after removal:   (125161, 9)\n",
      "CPU times: user 354 ms, sys: 6.85 ms, total: 361 ms\n",
      "Wall time: 362 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fracdocs = pd.DataFrame(app_freqs).fillna(value=0)\n",
    "n = 3000\n",
    "\n",
    "top_words = []\n",
    "for i in range(9):\n",
    "    tops = fracdocs[class_labels[i]].sort_values(ascending=False).head(n)\n",
    "    top_words.append(list(tops.index))\n",
    "\n",
    "overlap1 = set(top_words[0])\n",
    "for lis in top_words[1:]:\n",
    "    overlap1.intersection_update(lis)\n",
    "print('# intersecting words among top%d appearing words in each class: ', len(overlap1))\n",
    "    \n",
    "remove_list = []\n",
    "for i in range(9):\n",
    "    remove_words = [word for word in overlap1 \\\n",
    "                    if word in fracdocs[class_labels[i]] \\\n",
    "                    if fracdocs[class_labels[i]][word] > 0.5]\n",
    "    remove_list.append(list(remove_words))\n",
    "\n",
    "overlap2 = set(remove_list[0])\n",
    "for lis in remove_list[1:]:\n",
    "    overlap2.intersection_update(lis)\n",
    "print('# intersecting words with >50% appearance: ', len(overlap2))\n",
    "\n",
    "fracdocs_update1 = fracdocs.copy()\n",
    "fracdocs_update1 = fracdocs_update1.drop(overlap2)\n",
    "print('Table shape before removal: ', fracdocs.shape)\n",
    "print('Table shape after removal:  ', fracdocs_update1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fracdocs_update1.head()\n",
    "fracdocs_update1.to_csv('./data/app_freqs_update1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perdoc_apps = pd.DataFrame(ave_perdoc_apps).fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec1'></a>\n",
    "# 1. Extraction by fold difference  in frequency between classes\n",
    "(<a href='#sec0'>Back to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelativeDifference(a, b, freq_threshold=0.05):\n",
    "    if ((b != 0) and (a >= freq_threshold)):\n",
    "        return (a / b)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def getAbsoluteDifference(a, b, freq_threshold=0.05):\n",
    "    if ((a >= b ) and (a >= freq_threshold)):\n",
    "        return (a - b)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def decideOnDifference(a, b, freq_threshold, min_difference, mode='relative'):\n",
    "    if mode == 'relative':\n",
    "        difference = getRelativeDifference(a, b, freq_threshold=freq_threshold)\n",
    "        return (difference >= min_difference)\n",
    "    elif mode == 'absolute':\n",
    "        difference = getAbsoluteDifference(a, b, freq_threshold=freq_threshold)\n",
    "        return (difference >= min_difference)\n",
    "    else:\n",
    "        print('ERROR: Invalid mode')\n",
    "        return\n",
    "\n",
    "def get_nClassWords(docs, doc_type='fraction_of_docs', mode='relative',\n",
    "                    min_frequency=0.3, min_difference=1.5, print_result=True):\n",
    "    '''\n",
    "    This function looks at each word in each doc in the 'docs' and creates \n",
    "    a list containing frequency of appearance ('apps') for each class. The list is\n",
    "    re-order in descending order, and the fold difference between the adjacent pair\n",
    "    of frequencies are compared. If the fold difference is above a certain threshold\n",
    "    ('fold_threshold), the word is classified into a designated class of words.\n",
    "    When a word is classified as n-class word, it means that the freqs of app of the\n",
    "    word in n (number of) classes are X fold (fold_threshold) higher than those of \n",
    "    other classes. freq_threshold is a cutoff freq of app to decide whether to \n",
    "    include the word or not in the list. \n",
    "    \n",
    "    - Number of classes are assumed to be 9.\n",
    "    - Use get_FoldDifference function to calculate fold difference\n",
    "     \n",
    "    INPUTS:\n",
    "    ========\n",
    "    frac_docs : DataFrame\n",
    "        A list of lists containing fractions of docs a word appears in the class\n",
    "    \n",
    "    OUTPUTS:\n",
    "    ========\n",
    "    n_class_words : dictionary\n",
    "        A dictionary whose keys are n-class_word labels. Values a lists of words\n",
    "        in each of n classes of words\n",
    "    '''\n",
    "    min_freq = min_frequency\n",
    "    min_d = min_difference\n",
    "    mode = mode\n",
    "    \n",
    "    # Basic validation of input parameters\n",
    "    if doc_type == 'fraction_of_docs':\n",
    "        if ((min_freq < 0) or (min_freq > 1)):\n",
    "            print('ERROR: freq_threshold must be between 0 and 1')\n",
    "            return\n",
    "        #else:\n",
    "            #print('Doc Type: Fraction of Docs')\n",
    "    if doc_type == 'per_doc_frequency':\n",
    "        if (min_freq < 0):\n",
    "            print('ERROR: freq_threshold must be above 0')\n",
    "            return\n",
    "        #else:\n",
    "            #print('Doc Type: Per-doc Frequency')\n",
    "    else:\n",
    "        if not((doc_type == 'fraction_of_docs') or (doc_type == 'per_doc_frequency')):\n",
    "            print('ERROR: Invalid Doc Type')\n",
    "            return\n",
    "    \n",
    "    if not ((mode == 'relative') or (mode == 'absolute')):\n",
    "        print('ERROR: Invalid Mode')\n",
    "    \n",
    "    if ((doc_type == 'fraction_of_docs') and (mode == 'relative')):\n",
    "        if (min_freq*min_d) > 1:\n",
    "            print('ERROR: Fold difference too high. Lower min_difference')\n",
    "            return\n",
    "            \n",
    "    if ((doc_type == 'fraction_of_docs') and (mode == 'absolute')):\n",
    "        if (min_freq + min_d) > 1:\n",
    "            print('ERROR: Absolute difference too high. Lower min_difference')\n",
    "            return\n",
    "    \n",
    "    ncw_labels = ['one_class_words', 'two_class_words', 'three_class_words', \n",
    "                  'four_class_words', 'five_class_words', 'six_class_words', \n",
    "                  'seven_class_words', 'eight_class_words','other_words']\n",
    "\n",
    "    # Create a new dictionary to contain each n-class of words in list formats\n",
    "    n_class_words = {}\n",
    "    for i in range(9):\n",
    "        n_class_words[ncw_labels[i]] = []\n",
    "\n",
    "    # Get words for each n-class of words (might be a better way to do this?)\n",
    "    for j, word in enumerate(docs.index):\n",
    "        apps = np.array(docs.loc[word])\n",
    "        apps[::-1].sort()\n",
    "        if decideOnDifference(apps[0], apps[1], \n",
    "                              freq_threshold=min_freq, min_difference=min_d, mode=mode):\n",
    "            n_class_words[ncw_labels[0]].append(word)\n",
    "        elif decideOnDifference(apps[1], apps[2], \n",
    "                              freq_threshold=min_freq, min_difference=min_d, mode=mode):\n",
    "            n_class_words[ncw_labels[1]].append(word)\n",
    "        elif decideOnDifference(apps[2], apps[3], \n",
    "                              freq_threshold=min_freq, min_difference=min_d, mode=mode):\n",
    "            n_class_words[ncw_labels[2]].append(word)\n",
    "        elif decideOnDifference(apps[3], apps[4], \n",
    "                              freq_threshold=min_freq, min_difference=min_d, mode=mode):\n",
    "            n_class_words[ncw_labels[3]].append(word)\n",
    "        elif decideOnDifference(apps[4], apps[5], \n",
    "                              freq_threshold=min_freq, min_difference=min_d, mode=mode):\n",
    "            n_class_words[ncw_labels[4]].append(word)\n",
    "        elif decideOnDifference(apps[5], apps[6], \n",
    "                              freq_threshold=min_freq, min_difference=min_d, mode=mode):\n",
    "            n_class_words[ncw_labels[5]].append(word)\n",
    "        elif decideOnDifference(apps[6], apps[7], \n",
    "                              freq_threshold=min_freq, min_difference=min_d, mode=mode):\n",
    "            n_class_words[ncw_labels[6]].append(word)\n",
    "        elif decideOnDifference(apps[7], apps[8], \n",
    "                              freq_threshold=min_freq, min_difference=min_d, mode=mode):\n",
    "            n_class_words[ncw_labels[7]].append(word)\n",
    "        else:\n",
    "            n_class_words[ncw_labels[8]].append(word)\n",
    "    \n",
    "    # Remove a list of words from one-class words\n",
    "    one_class_remove_list = ['bunkyo', 'commonest', 'commonplac', 'concret', 'consol',\n",
    "                             'conspicu', 'credenc', 'damage—unlik', 'drew', 'enumer', 'logo', \n",
    "                             'graduat','ibaraki', 'joshi', 'kaneda', 'kurumizaka', 'lesson', \n",
    "                             'matsui', 'minami', 'minato', 'montreal', 'newyork', 'ontario', \n",
    "                             'shirokanedai', 'sinai', 'taipei', 'wake', 'wise', 'yokohama']\n",
    "    n_class_words['one_class_words'] = [word for word in n_class_words['one_class_words'] if len(word) > 2]\n",
    "    \n",
    "    if print_result:\n",
    "        print('======== n-class words extractions by %s differecne ========' % mode)\n",
    "        print('Input Type: %s' % doc_type)\n",
    "        print('Minimum Difference = %.2f' % min_d)\n",
    "        print('Minimum Frequency = %.2f' % min_freq)\n",
    "        total = 0\n",
    "        for i in range(9):\n",
    "            print('# of words in %s: %d' % (ncw_labels[i], len(n_class_words[ncw_labels[i]])))\n",
    "            total += len(n_class_words[ncw_labels[i]])\n",
    "        print('Total # of words: %d' % total)\n",
    "    \n",
    "    return n_class_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== n-class words extractions by relative differecne ========\n",
      "Minimum Difference = 1.400000\n",
      "Minimum Frequency = 0.350000\n",
      "# of words in one_class_words: 312\n",
      "# of words in two_class_words: 117\n",
      "# of words in three_class_words: 11\n",
      "# of words in four_class_words: 14\n",
      "# of words in five_class_words: 11\n",
      "# of words in six_class_words: 6\n",
      "# of words in seven_class_words: 25\n",
      "# of words in eight_class_words: 69\n",
      "# of words in other_words: 124581\n",
      "Total # of words: 125146\n",
      "\n",
      "\n",
      "======== n-class words extractions by absolute differecne ========\n",
      "Minimum Difference = 0.200000\n",
      "Minimum Frequency = 0.350000\n",
      "# of words in one_class_words: 186\n",
      "# of words in two_class_words: 56\n",
      "# of words in three_class_words: 2\n",
      "# of words in four_class_words: 2\n",
      "# of words in five_class_words: 1\n",
      "# of words in six_class_words: 1\n",
      "# of words in seven_class_words: 2\n",
      "# of words in eight_class_words: 16\n",
      "# of words in other_words: 124885\n",
      "Total # of words: 125151\n",
      "\n",
      "\n",
      "======== n-class words extractions by relative differecne ========\n",
      "Minimum Difference = 5.000000\n",
      "Minimum Frequency = 2.000000\n",
      "# of words in one_class_words: 102\n",
      "# of words in two_class_words: 39\n",
      "# of words in three_class_words: 2\n",
      "# of words in four_class_words: 3\n",
      "# of words in five_class_words: 5\n",
      "# of words in six_class_words: 1\n",
      "# of words in seven_class_words: 0\n",
      "# of words in eight_class_words: 1\n",
      "# of words in other_words: 125285\n",
      "Total # of words: 125438\n",
      "\n",
      "\n",
      "======== n-class words extractions by absolute differecne ========\n",
      "Minimum Difference = 3.000000\n",
      "Minimum Frequency = 2.000000\n",
      "# of words in one_class_words: 246\n",
      "# of words in two_class_words: 54\n",
      "# of words in three_class_words: 6\n",
      "# of words in four_class_words: 1\n",
      "# of words in five_class_words: 1\n",
      "# of words in six_class_words: 2\n",
      "# of words in seven_class_words: 1\n",
      "# of words in eight_class_words: 3\n",
      "# of words in other_words: 125120\n",
      "Total # of words: 125434\n",
      "CPU times: user 35.9 s, sys: 127 ms, total: 36 s\n",
      "Wall time: 35.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_class_words = get_nClassWords(fracdocs_update1, doc_type='fraction_of_docs', mode='relative',\n",
    "                                min_frequency=0.35, min_difference=1.4, print_result=True)\n",
    "print('\\n')\n",
    "n_class_words = get_nClassWords(fracdocs_update1, doc_type='fraction_of_docs', mode='absolute',\n",
    "                                min_frequency=0.35, min_difference=0.2, print_result=True)\n",
    "print('\\n')\n",
    "n_class_words = get_nClassWords(perdoc_apps, doc_type='per_doc_frequency', mode='relative',\n",
    "                                min_frequency=2, min_difference=5, print_result=True)\n",
    "print('\\n')\n",
    "n_class_words = get_nClassWords(perdoc_apps, doc_type='per_doc_frequency', mode='absolute',\n",
    "                                min_frequency=2, min_difference=3, print_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== n-class words extractions by relative differecne ========\n",
      "Minimum Difference = 5.000000\n",
      "Minimum Frequency = 1.000000\n",
      "# of words in one_class_words: 220\n",
      "# of words in two_class_words: 77\n",
      "# of words in three_class_words: 7\n",
      "# of words in four_class_words: 4\n",
      "# of words in five_class_words: 11\n",
      "# of words in six_class_words: 3\n",
      "# of words in seven_class_words: 0\n",
      "# of words in eight_class_words: 4\n",
      "# of words in other_words: 125105\n",
      "Total # of words: 125431\n",
      "CPU times: user 8.92 s, sys: 12.8 ms, total: 8.94 s\n",
      "Wall time: 8.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_class_words = get_nClassWords(perdoc_apps, doc_type='per_doc_frequency', mode='relative',\n",
    "                                min_frequency=1, min_difference=5, print_result=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec2'></a>\n",
    "# 2. Extraction by exclusive appearance in certain classes\n",
    "(<a href='#sec0'>Back to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nClassExclusiveWords(docs, min_frequency=0.2, print_result=True):\n",
    "    '''\n",
    "    This function looks at each word in each doc in the 'docs' and creates \n",
    "    a list containing frequency of appearance ('apps') for each class. Then,\n",
    "    the number of non-zero freqs in the list is counted. That number is used\n",
    "    to classified the word as n-class word. In this case, n-class word is a\n",
    "    word that appears only in n number of classes. freq_threshold parameter \n",
    "    is a cutoff freq of app to decide whether to include the word or not in \n",
    "    the list. \n",
    "    \n",
    "    - Number of classes are assumed to be 9\n",
    "    - This function can be used for both 'fraction_of_docs' and 'perdoc_apps'\n",
    "      types of inputs\n",
    "    \n",
    "    INPUTS:\n",
    "    ========\n",
    "    frac_docs : DataFrame\n",
    "        A list of lists containing fractions of docs a word appears in the class\n",
    "    \n",
    "    OUTPUTS:\n",
    "    ========\n",
    "    n_class_words : dictionary\n",
    "        A dictionary whose keys are n-class_word labels. Values a lists of words\n",
    "        in each of n classes of words\n",
    "        \n",
    "    '''\n",
    "    min_freq = min_frequency\n",
    "\n",
    "    ncw_labels = ['one_class_words', 'two_class_words', 'three_class_words', \n",
    "                  'four_class_words', 'five_class_words', 'six_class_words', \n",
    "                  'seven_class_words', 'eight_class_words','other_words']\n",
    "\n",
    "    # Create a new dictionary to contain each n-class of words in list formats\n",
    "    n_class_words = {}\n",
    "    for i in range(9):\n",
    "        n_class_words[ncw_labels[i]] = []\n",
    "\n",
    "    # Get words for each n-class of words\n",
    "    for j, word in enumerate(docs.index):\n",
    "        apps = np.array(docs.loc[word])\n",
    "        num_nonzeros = np.count_nonzero(apps)\n",
    "        if np.min(apps[np.nonzero(apps)]) >= min_freq:\n",
    "            n_class_words[ncw_labels[(num_nonzeros-1)]].append(word)\n",
    "        else:\n",
    "            n_class_words[ncw_labels[8]].append(word)\n",
    "    \n",
    "    # Remove a list of words from one-class words\n",
    "    one_class_remove_list = ['bunkyo', 'commonest', 'commonplac', 'concret', 'consol',\n",
    "                             'conspicu', 'credenc', 'damage—unlik', 'drew', 'enumer', 'logo', \n",
    "                             'graduat','ibaraki', 'joshi', 'kaneda', 'kurumizaka', 'lesson', \n",
    "                             'matsui', 'minami', 'minato', 'montreal', 'newyork', 'ontario', \n",
    "                             'shirokanedai', 'sinai', 'taipei', 'wake', 'wise', 'yokohama']\n",
    "    n_class_words['one_class_words'] = [word for word in n_class_words['one_class_words'] if len(word) > 2]\n",
    "    \n",
    "    if print_result:\n",
    "        print('======== n-class words extractions by exclusive appearances ========')\n",
    "        print('Minimum Frequency = %f' % min_freq)\n",
    "        total = 0\n",
    "        for i in range(9):\n",
    "            print('# of words in %s: %d' % (ncw_labels[i], len(n_class_words[ncw_labels[i]])))\n",
    "            total += len(n_class_words[ncw_labels[i]])\n",
    "        print('Total # of words: %d' % total)\n",
    "    \n",
    "    return n_class_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== n-class words extractions by exclusive appearances ========\n",
      "Minimum Frequency = 0.150000\n",
      "# of words in one_class_words: 264\n",
      "# of words in two_class_words: 4\n",
      "# of words in three_class_words: 0\n",
      "# of words in four_class_words: 0\n",
      "# of words in five_class_words: 0\n",
      "# of words in six_class_words: 0\n",
      "# of words in seven_class_words: 0\n",
      "# of words in eight_class_words: 3\n",
      "# of words in other_words: 124890\n",
      "Total # of words: 125161\n",
      "CPU times: user 9.64 s, sys: 53.6 ms, total: 9.69 s\n",
      "Wall time: 9.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "min_freq = 0.15\n",
    "n_class_words = get_nClassExclusiveWords(fracdocs_update1, min_frequency=min_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='sec3'></a>\n",
    "# 3. Classification with Random Forest Classifier\n",
    "(<a href='#sec0'>Back to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='sec3_1'></a>\n",
    "## 1. RFC with exclusive words\n",
    "- Write a function to iterate over min_frequency space\n",
    "- Try both with fraction of documents appearing and per-doc frequency\n",
    "\n",
    "(<a href='#sec0'>Back to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ncw_labels = ['one_class_words', 'two_class_words', 'three_class_words', \n",
    "                  'four_class_words', 'five_class_words', 'six_class_words', \n",
    "                  'seven_class_words', 'eight_class_words','other_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RFC_nWordsExclusive(main_docs, freq_docs, classes, min_frequency=0.15, n_class=1):\n",
    "    # Words to create features\n",
    "    #print('Extracting exclusive words...')\n",
    "    exclusive_words = get_nClassExclusiveWords(freq_docs, min_frequency=min_frequency,\n",
    "                                               print_result=False)\n",
    "    select_words = []\n",
    "    for i in range(n_class):\n",
    "        select_words += exclusive_words[ncw_labels[i]]\n",
    "    if len(select_words) == 0:\n",
    "        print('No words extraced. Process terminated.')\n",
    "        return\n",
    "    \n",
    "    #print('%d words extracted...' % len(select_words))\n",
    "        \n",
    "    # pre-process the raw texts\n",
    "    #print('Pre-processing texts...')\n",
    "    unclf_docs2 = []\n",
    "    for j, doc in enumerate(main_docs):\n",
    "        doc = [word for word in doc if word in select_words]\n",
    "        text = ' '.join(doc)\n",
    "        unclf_docs2.append(text)\n",
    "    \n",
    "    # Vectroize by Frequency Counts\n",
    "    #print('Vectorizating texts...')\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(unclf_docs2).toarray()\n",
    "    \n",
    "    # Run RFC on the data\n",
    "    #print('Training the classifier...')\n",
    "    X = X.astype(float)\n",
    "    y = classes\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "    rfc = RandomForestClassifier(n_estimators=100, max_depth=50, n_jobs=7, random_state=33)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    \n",
    "    #print('Making predictions...')\n",
    "    accuracy = accuracy_score(y_test, rfc.predict(X_test))\n",
    "    lloss = log_loss(y_test, rfc.predict_proba(X_test), labels=list(range(1, 10)))\n",
    "    \n",
    "    #print('===== Prediction Result =====')\n",
    "    print(' - Accuracyl: %.3f' % accuracy)\n",
    "    print(' - Log Loss: %.3f' % lloss)\n",
    "    \n",
    "    return [accuracy, lloss]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with fraction of documents appearing (min_freq = 0.1 ~0.16, n_class = 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Processing: min_freq=0.10, n_class=1 =====\n",
      "Extracting exclusive words...\n",
      "335 words extracted...\n",
      "Pre-processing texts...\n",
      "Vectorizating texts...\n",
      "Training the classifier...\n",
      "Making predictions...\n",
      "===== Prediction Result =====\n",
      " - Accuracyl: 0.323\n",
      " - Log Loss: 1.776\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.11, n_class=1 =====\n",
      "Extracting exclusive words...\n",
      "312 words extracted...\n",
      "Pre-processing texts...\n",
      "Vectorizating texts...\n",
      "Training the classifier...\n",
      "Making predictions...\n",
      "===== Prediction Result =====\n",
      " - Accuracyl: 0.303\n",
      " - Log Loss: 1.762\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.12, n_class=1 =====\n",
      "Extracting exclusive words...\n",
      "312 words extracted...\n",
      "Pre-processing texts...\n",
      "Vectorizating texts...\n",
      "Training the classifier...\n",
      "Making predictions...\n",
      "===== Prediction Result =====\n",
      " - Accuracyl: 0.283\n",
      " - Log Loss: 1.771\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.13, n_class=1 =====\n",
      "Extracting exclusive words...\n",
      "312 words extracted...\n",
      "Pre-processing texts...\n",
      "Vectorizating texts...\n",
      "Training the classifier...\n",
      "Making predictions...\n",
      "===== Prediction Result =====\n",
      " - Accuracyl: 0.349\n",
      " - Log Loss: 1.755\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.14, n_class=1 =====\n",
      "Extracting exclusive words...\n",
      "264 words extracted...\n",
      "Pre-processing texts...\n",
      "Vectorizating texts...\n",
      "Training the classifier...\n",
      "Making predictions...\n",
      "===== Prediction Result =====\n",
      " - Accuracyl: 0.259\n",
      " - Log Loss: 1.813\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.15, n_class=1 =====\n",
      "Extracting exclusive words...\n",
      "264 words extracted...\n",
      "Pre-processing texts...\n",
      "Vectorizating texts...\n",
      "Training the classifier...\n",
      "Making predictions...\n",
      "===== Prediction Result =====\n",
      " - Accuracyl: 0.329\n",
      " - Log Loss: 1.788\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.16, n_class=1 =====\n",
      "Extracting exclusive words...\n",
      "110 words extracted...\n",
      "Pre-processing texts...\n",
      "Vectorizating texts...\n",
      "Training the classifier...\n",
      "Making predictions...\n",
      "===== Prediction Result =====\n",
      " - Accuracyl: 0.281\n",
      " - Log Loss: 1.850\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.10, n_class=2 =====\n",
      "Extracting exclusive words...\n",
      "348 words extracted...\n",
      "Pre-processing texts...\n",
      "Vectorizating texts...\n",
      "Training the classifier...\n",
      "Making predictions...\n",
      "===== Prediction Result =====\n",
      " - Accuracyl: 0.295\n",
      " - Log Loss: 1.826\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.11, n_class=2 =====\n",
      "Extracting exclusive words...\n",
      "316 words extracted...\n",
      "Pre-processing texts...\n",
      "Vectorizating texts...\n",
      "Training the classifier...\n",
      "Making predictions...\n",
      "===== Prediction Result =====\n",
      " - Accuracyl: 0.325\n",
      " - Log Loss: 1.774\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.12, n_class=2 =====\n",
      "Extracting exclusive words...\n",
      "316 words extracted...\n",
      "Pre-processing texts...\n",
      "Vectorizating texts...\n",
      "Training the classifier...\n",
      "Making predictions...\n",
      "===== Prediction Result =====\n",
      " - Accuracyl: 0.309\n",
      " - Log Loss: 1.775\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.13, n_class=2 =====\n",
      "Extracting exclusive words...\n",
      "316 words extracted...\n",
      "Pre-processing texts...\n",
      "Vectorizating texts...\n",
      "Training the classifier...\n",
      "Making predictions...\n",
      "===== Prediction Result =====\n",
      " - Accuracyl: 0.307\n",
      " - Log Loss: 1.779\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.14, n_class=2 =====\n",
      "Extracting exclusive words...\n",
      "268 words extracted...\n",
      "Pre-processing texts...\n",
      "Vectorizating texts...\n",
      "Training the classifier...\n",
      "Making predictions...\n",
      "===== Prediction Result =====\n",
      " - Accuracyl: 0.329\n",
      " - Log Loss: 1.778\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.15, n_class=2 =====\n",
      "Extracting exclusive words...\n",
      "268 words extracted...\n",
      "Pre-processing texts...\n",
      "Vectorizating texts...\n",
      "Training the classifier...\n",
      "Making predictions...\n",
      "===== Prediction Result =====\n",
      " - Accuracyl: 0.299\n",
      " - Log Loss: 1.809\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.16, n_class=2 =====\n",
      "Extracting exclusive words...\n",
      "110 words extracted...\n",
      "Pre-processing texts...\n",
      "Vectorizating texts...\n",
      "Training the classifier...\n",
      "Making predictions...\n",
      "===== Prediction Result =====\n",
      " - Accuracyl: 0.265\n",
      " - Log Loss: 1.866\n",
      "\n",
      "\n",
      "CPU times: user 14min, sys: 1.32 s, total: 14min 1s\n",
      "Wall time: 13min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = []\n",
    "metrics = {}\n",
    "y = np.array(class_train.Class).astype(int).ravel()\n",
    "\n",
    "for i in range(2):\n",
    "    n_class = i + 1\n",
    "    freq_space = np.linspace(0.1, 0.16, 7)\n",
    "    for j, freq in enumerate(freq_space):\n",
    "        print('===== Processing: min_freq=%.2f, n_class=%d =====' % (freq, n_class))\n",
    "        param = (freq, n_class)\n",
    "        params.append(param)\n",
    "        scores = RFC_nWordsExclusive(unclassified_tokenized_docs, fracdocs_update1, y, min_frequency=freq, n_class=n_class)\n",
    "        metrics[param] = scores\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with per-doc frequency (min_freq = 0.5~2, n_class = 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Processing: min_freq=0.50, n_class=1 =====\n",
      " - Accuracyl: 0.295\n",
      " - Log Loss: 1.802\n",
      "\n",
      "\n",
      "===== Processing: min_freq=1.00, n_class=1 =====\n",
      " - Accuracyl: 0.329\n",
      " - Log Loss: 1.746\n",
      "\n",
      "\n",
      "===== Processing: min_freq=1.50, n_class=1 =====\n",
      " - Accuracyl: 0.271\n",
      " - Log Loss: 1.865\n",
      "\n",
      "\n",
      "===== Processing: min_freq=2.00, n_class=1 =====\n",
      " - Accuracyl: 0.299\n",
      " - Log Loss: 1.786\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.50, n_class=2 =====\n",
      " - Accuracyl: 0.293\n",
      " - Log Loss: 1.779\n",
      "\n",
      "\n",
      "===== Processing: min_freq=1.00, n_class=2 =====\n",
      " - Accuracyl: 0.299\n",
      " - Log Loss: 1.797\n",
      "\n",
      "\n",
      "===== Processing: min_freq=1.50, n_class=2 =====\n",
      " - Accuracyl: 0.293\n",
      " - Log Loss: 1.832\n",
      "\n",
      "\n",
      "===== Processing: min_freq=2.00, n_class=2 =====\n",
      " - Accuracyl: 0.295\n",
      " - Log Loss: 1.799\n",
      "\n",
      "\n",
      "CPU times: user 2min 23s, sys: 644 ms, total: 2min 23s\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = []\n",
    "metrics = {}\n",
    "y = np.array(class_train.Class).astype(int).ravel()\n",
    "\n",
    "for i in range(2):\n",
    "    n_class = i + 1\n",
    "    freq_space = [0.5, 1, 1.5, 2]\n",
    "    for j, freq in enumerate(freq_space):\n",
    "        print('===== Processing: min_freq=%.2f, n_class=%d =====' % (freq, n_class))\n",
    "        param = (freq, n_class)\n",
    "        params.append(param)\n",
    "        scores = RFC_nWordsExclusive(unclassified_tokenized_docs, perdoc_apps, y, min_frequency=freq, n_class=n_class)\n",
    "        metrics[param] = scores\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Looks like exclusive words don't seem to work or their frequencies are too low...\n",
    "Try with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This version uses TfidfVectorizer\n",
    "def RFC_nWordsExclusive2(main_docs, freq_docs, classes, min_frequency=0.15, n_class=1):\n",
    "    # Words to create features\n",
    "    #print('Extracting exclusive words...')\n",
    "    exclusive_words = get_nClassExclusiveWords(freq_docs, min_frequency=min_frequency,\n",
    "                                               print_result=False)\n",
    "    select_words = []\n",
    "    for i in range(n_class):\n",
    "        select_words += exclusive_words[ncw_labels[i]]\n",
    "    if len(select_words) == 0:\n",
    "        print('No words extraced. Process terminated.')\n",
    "        return\n",
    "    \n",
    "    print('%d words extracted...' % len(select_words))\n",
    "        \n",
    "    # pre-process the raw texts\n",
    "    #print('Pre-processing texts...')\n",
    "    unclf_docs2 = []\n",
    "    for j, doc in enumerate(main_docs):\n",
    "        doc = [word for word in doc if word in select_words]\n",
    "        text = ' '.join(doc)\n",
    "        unclf_docs2.append(text)\n",
    "    \n",
    "    # Vectroize by Frequency Counts\n",
    "    #print('Vectorizating texts...')\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(unclf_docs2).toarray()\n",
    "    \n",
    "    # Run RFC on the data\n",
    "    #print('Training the classifier...')\n",
    "    X = X.astype(float)\n",
    "    y = classes\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "    rfc = RandomForestClassifier(n_estimators=100, max_depth=50, n_jobs=7, random_state=33)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    \n",
    "    #print('Making predictions...')\n",
    "    accuracy = accuracy_score(y_test, rfc.predict(X_test))\n",
    "    lloss = log_loss(y_test, rfc.predict_proba(X_test), labels=list(range(1, 10)))\n",
    "    \n",
    "    #print('===== Prediction Result =====')\n",
    "    print(' - Accuracyl: %.3f' % accuracy)\n",
    "    print(' - Log Loss: %.3f' % lloss)\n",
    "    \n",
    "    return [accuracy, lloss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Processing: min_freq=0.10, n_class=1 =====\n",
      "335 words extracted...\n",
      " - Accuracyl: 0.337\n",
      " - Log Loss: 1.743\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.11, n_class=1 =====\n",
      "312 words extracted...\n",
      " - Accuracyl: 0.303\n",
      " - Log Loss: 1.783\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.12, n_class=1 =====\n",
      "312 words extracted...\n",
      " - Accuracyl: 0.259\n",
      " - Log Loss: 1.807\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.13, n_class=1 =====\n",
      "312 words extracted...\n",
      " - Accuracyl: 0.331\n",
      " - Log Loss: 1.771\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.14, n_class=1 =====\n",
      "264 words extracted...\n",
      " - Accuracyl: 0.295\n",
      " - Log Loss: 1.818\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.15, n_class=1 =====\n",
      "264 words extracted...\n",
      " - Accuracyl: 0.301\n",
      " - Log Loss: 1.784\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.16, n_class=1 =====\n",
      "110 words extracted...\n",
      " - Accuracyl: 0.305\n",
      " - Log Loss: 1.812\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.10, n_class=2 =====\n",
      "348 words extracted...\n",
      " - Accuracyl: 0.285\n",
      " - Log Loss: 1.787\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.11, n_class=2 =====\n",
      "316 words extracted...\n",
      " - Accuracyl: 0.271\n",
      " - Log Loss: 1.815\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.12, n_class=2 =====\n",
      "316 words extracted...\n",
      " - Accuracyl: 0.313\n",
      " - Log Loss: 1.778\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.13, n_class=2 =====\n",
      "316 words extracted...\n",
      " - Accuracyl: 0.333\n",
      " - Log Loss: 1.764\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.14, n_class=2 =====\n",
      "268 words extracted...\n",
      " - Accuracyl: 0.271\n",
      " - Log Loss: 1.833\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.15, n_class=2 =====\n",
      "268 words extracted...\n",
      " - Accuracyl: 0.287\n",
      " - Log Loss: 1.796\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.16, n_class=2 =====\n",
      "110 words extracted...\n",
      " - Accuracyl: 0.335\n",
      " - Log Loss: 1.794\n",
      "\n",
      "\n",
      "CPU times: user 14min 5s, sys: 1.08 s, total: 14min 6s\n",
      "Wall time: 14min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = []\n",
    "metrics = {}\n",
    "y = np.array(class_train.Class).astype(int).ravel()\n",
    "\n",
    "for i in range(2):\n",
    "    n_class = i + 1\n",
    "    freq_space = np.linspace(0.1, 0.16, 7)\n",
    "    for j, freq in enumerate(freq_space):\n",
    "        print('===== Processing: min_freq=%.2f, n_class=%d =====' % (freq, n_class))\n",
    "        param = (freq, n_class)\n",
    "        params.append(param)\n",
    "        scores = RFC_nWordsExclusive2(unclassified_tokenized_docs, fracdocs_update1, y, min_frequency=freq, n_class=n_class)\n",
    "        metrics[param] = scores\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still no good..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec3_2'></a>\n",
    "## 2. RFC with words selected by relative difference - fraction of docs appearing\n",
    "- Write a function to iterate over min_frequency space\n",
    "- Try both with fraction of documents appearing\n",
    "\n",
    "(<a href='#sec0'>Back to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version uses TfidfVectorizer\n",
    "def RFC_nClassWords(main_docs, freq_docs, classes, vectorizer='count',\n",
    "                    min_difference=1.5, min_frequency=0.35, n_class=1):\n",
    "    # Words to create features\n",
    "    #print('Extracting exclusive words...')\n",
    "    nclass_words = get_nClassWords(freq_docs, doc_type='fraction_of_docs', mode='relative',\n",
    "                                   min_frequency=min_frequency, min_difference=min_difference, print_result=False)\n",
    "    select_words = []\n",
    "    for i in range(n_class):\n",
    "        select_words += nclass_words[ncw_labels[i]]\n",
    "    if len(select_words) == 0:\n",
    "        print('No words extraced. Process terminated.')\n",
    "        return\n",
    "    \n",
    "    print('%d words extracted...' % len(select_words))\n",
    "        \n",
    "    # pre-process the raw texts\n",
    "    #print('Pre-processing texts...')\n",
    "    unclf_docs2 = []\n",
    "    for j, doc in enumerate(main_docs):\n",
    "        doc = [word for word in doc if word in select_words]\n",
    "        text = ' '.join(doc)\n",
    "        unclf_docs2.append(text)\n",
    "    \n",
    "    # Vectroize by Frequency Counts\n",
    "    #print('Vectorizating texts...')\n",
    "    if vectorizer == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer()\n",
    "    else:\n",
    "        vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(unclf_docs2).toarray()\n",
    "    \n",
    "    # Run RFC on the data\n",
    "    #print('Training the classifier...')\n",
    "    X = X.astype(float)\n",
    "    y = classes\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "    rfc = RandomForestClassifier(n_estimators=100, max_depth=50, n_jobs=7, random_state=33)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    \n",
    "    #print('Making predictions...')\n",
    "    accuracy = accuracy_score(y_test, rfc.predict(X_test))\n",
    "    lloss = log_loss(y_test, rfc.predict_proba(X_test), labels=list(range(1, 10)))\n",
    "    \n",
    "    #print('===== Prediction Result =====')\n",
    "    print(' - Accuracyl: %.3f' % accuracy)\n",
    "    print(' - Log Loss: %.3f' % lloss)\n",
    "    \n",
    "    return [accuracy, lloss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Processing: min_freq=0.35, fold_diff=2.00, n_class=1 =====\n",
      "116 words extracted...\n",
      " - Accuracyl: 0.605\n",
      " - Log Loss: 1.711\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.35, fold_diff=1.80, n_class=1 =====\n",
      "145 words extracted...\n",
      " - Accuracyl: 0.611\n",
      " - Log Loss: 1.378\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.35, fold_diff=1.60, n_class=1 =====\n",
      "214 words extracted...\n",
      " - Accuracyl: 0.611\n",
      " - Log Loss: 1.456\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.35, fold_diff=1.40, n_class=1 =====\n",
      "312 words extracted...\n",
      " - Accuracyl: 0.617\n",
      " - Log Loss: 1.716\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.35, fold_diff=1.20, n_class=1 =====\n",
      "599 words extracted...\n",
      " - Accuracyl: 0.629\n",
      " - Log Loss: 1.666\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.35, fold_diff=2.00, n_class=2 =====\n",
      "147 words extracted...\n",
      " - Accuracyl: 0.577\n",
      " - Log Loss: 1.754\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.35, fold_diff=1.80, n_class=2 =====\n",
      "187 words extracted...\n",
      " - Accuracyl: 0.629\n",
      " - Log Loss: 1.572\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.35, fold_diff=1.60, n_class=2 =====\n",
      "285 words extracted...\n",
      " - Accuracyl: 0.625\n",
      " - Log Loss: 1.556\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.35, fold_diff=1.40, n_class=2 =====\n",
      "429 words extracted...\n",
      " - Accuracyl: 0.659\n",
      " - Log Loss: 1.448\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.35, fold_diff=1.20, n_class=2 =====\n",
      "798 words extracted...\n",
      " - Accuracyl: 0.629\n",
      " - Log Loss: 1.872\n",
      "\n",
      "\n",
      "CPU times: user 12min 12s, sys: 425 ms, total: 12min 13s\n",
      "Wall time: 12min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = []\n",
    "metrics = {}\n",
    "y = np.array(class_train.Class).astype(int).ravel()\n",
    "\n",
    "min_freq = 0.35\n",
    "for i in range(2):\n",
    "    n_class = i + 1\n",
    "    diff_space = [2, 1.8, 1.6, 1.4, 1.2]\n",
    "    for j, diff in enumerate(diff_space):\n",
    "        print('===== Processing: min_freq=%.2f, fold_diff=%.2f, n_class=%d =====' % (min_freq, diff, n_class))\n",
    "        param = (min_freq, diff, n_class)\n",
    "        params.append(param)\n",
    "        scores = RFC_nClassWords(unclassified_tokenized_docs, fracdocs_update1, y, min_difference=diff, min_frequency=0.35, n_class=n_class)\n",
    "        metrics[param] = scores\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Processing: min_freq=0.30, fold_diff=1.60, n_class=1 =====\n",
      "283 words extracted...\n",
      " - Accuracyl: 0.625\n",
      " - Log Loss: 1.475\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.30, fold_diff=1.50, n_class=1 =====\n",
      "335 words extracted...\n",
      " - Accuracyl: 0.643\n",
      " - Log Loss: 1.597\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.30, fold_diff=1.40, n_class=1 =====\n",
      "414 words extracted...\n",
      " - Accuracyl: 0.603\n",
      " - Log Loss: 2.146\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.35, fold_diff=1.60, n_class=1 =====\n",
      "214 words extracted...\n",
      " - Accuracyl: 0.597\n",
      " - Log Loss: 1.549\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.35, fold_diff=1.50, n_class=1 =====\n",
      "248 words extracted...\n",
      " - Accuracyl: 0.597\n",
      " - Log Loss: 1.959\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.35, fold_diff=1.40, n_class=1 =====\n",
      "312 words extracted...\n",
      " - Accuracyl: 0.659\n",
      " - Log Loss: 1.269\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.40, fold_diff=1.60, n_class=1 =====\n",
      "133 words extracted...\n",
      " - Accuracyl: 0.637\n",
      " - Log Loss: 1.464\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.40, fold_diff=1.50, n_class=1 =====\n",
      "161 words extracted...\n",
      " - Accuracyl: 0.613\n",
      " - Log Loss: 1.517\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.40, fold_diff=1.40, n_class=1 =====\n",
      "210 words extracted...\n",
      " - Accuracyl: 0.647\n",
      " - Log Loss: 1.414\n",
      "\n",
      "\n",
      "CPU times: user 9min 2s, sys: 399 ms, total: 9min 3s\n",
      "Wall time: 8min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = []\n",
    "metrics = {}\n",
    "y = np.array(class_train.Class).astype(int).ravel()\n",
    "\n",
    "n_class = 1 \n",
    "freqs = [0.3, 0.35, 0.4]\n",
    "diff_space = [1.6, 1.5, 1.4]\n",
    "for i, freq in enumerate(freqs):\n",
    "    for j, diff in enumerate(diff_space):\n",
    "        print('===== Processing: min_freq=%.2f, fold_diff=%.2f, n_class=%d =====' % (freq, diff, n_class))\n",
    "        param = (freq, diff, n_class)\n",
    "        params.append(param)\n",
    "        scores = RFC_nClassWords(unclassified_tokenized_docs, fracdocs_update1, y, vectorizer='tfidf',\n",
    "                                 min_difference=diff, min_frequency=freq, n_class=n_class)\n",
    "        metrics[param] = scores\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Processing: min_freq=0.35, fold_diff=1.40, n_class=1 =====\n",
      "312 words extracted...\n",
      " - Accuracyl: 0.613\n",
      " - Log Loss: 1.389\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.35, fold_diff=1.40, n_class=2 =====\n",
      "429 words extracted...\n",
      " - Accuracyl: 0.633\n",
      " - Log Loss: 1.370\n",
      "\n",
      "\n",
      "===== Processing: min_freq=0.35, fold_diff=1.40, n_class=3 =====\n",
      "440 words extracted...\n",
      " - Accuracyl: 0.597\n",
      " - Log Loss: 1.554\n",
      "\n",
      "\n",
      "CPU times: user 4min 22s, sys: 95.1 ms, total: 4min 22s\n",
      "Wall time: 4min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = []\n",
    "metrics = {}\n",
    "y = np.array(class_train.Class).astype(int).ravel()\n",
    "\n",
    "n_class = [1, 2, 3] \n",
    "freq = 0.35\n",
    "diff = 1.4\n",
    "for i, n in enumerate(n_class):\n",
    "    print('===== Processing: min_freq=%.2f, fold_diff=%.2f, n_class=%d =====' % (freq, diff, n))\n",
    "    param = (freq, diff, n)\n",
    "    params.append(param)\n",
    "    scores = RFC_nClassWords(unclassified_tokenized_docs, fracdocs_update1, y, vectorizer='tfidf',\n",
    "                             min_difference=diff, min_frequency=freq, n_class=n)\n",
    "    metrics[param] = scores\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minimum frequency of 0.35, fold difference of 1.4, and inclusion of 2-class words seems to be best, which is similar to what I got before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
